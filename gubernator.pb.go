// Code generated by protoc-gen-go. DO NOT EDIT.
// source: gubernator.proto

package gubernator

import (
	context "context"
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

type Algorithm int32

const (
	// Token bucket algorithm https://en.wikipedia.org/wiki/Token_bucket
	Algorithm_TOKEN_BUCKET Algorithm = 0
	// Leaky bucket algorithm https://en.wikipedia.org/wiki/Leaky_bucket
	Algorithm_LEAKY_BUCKET Algorithm = 1
)

var Algorithm_name = map[int32]string{
	0: "TOKEN_BUCKET",
	1: "LEAKY_BUCKET",
}

var Algorithm_value = map[string]int32{
	"TOKEN_BUCKET": 0,
	"LEAKY_BUCKET": 1,
}

func (x Algorithm) String() string {
	return proto.EnumName(Algorithm_name, int32(x))
}

func (Algorithm) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{0}
}

// A set of int32 flags used to control the behavior of a rate limit in gubernator
type Behavior int32

const (
	// BATCHING is the default behavior. This enables batching requests which protects the
	// service from thundering herd. IE: When a service experiences spikes of unexpected high
	// volume requests.
	//
	// Using this option introduces a small amount of latency depending on
	// the `batchWait` setting. Defaults to around 500 Microseconds of additional
	// latency in low throughput situations. For high volume loads, batching can reduce
	// the overall load on the system substantially.
	Behavior_BATCHING Behavior = 0
	// Disables batching. Use this for super low latency rate limit requests when
	// thundering herd is not a concern but latency of requests is of paramount importance.
	Behavior_NO_BATCHING Behavior = 1
	// Enables Global caching of the rate limit. Use this if the rate limit applies globally to
	// all ingress requests. (IE: Throttle hundreds of thousands of requests to an entire
	// datacenter or cluster of http servers)
	//
	// Using this option gubernator will continue to use a single peer as the rate limit coordinator
	// to increment and manage the state of the rate limit, however the result of the rate limit is
	// distributed to each peer and cached locally. A rate limit request received from any peer in the
	// cluster will first check the local cache for a rate limit answer, if it exists the peer will
	// immediately return the answer to the client and asynchronously forward the aggregate hits to
	// the peer coordinator. Because of GLOBALS async nature we lose some accuracy in rate limit
	// reporting, which may result in allowing some requests beyond the chosen rate limit. However we
	// gain massive performance as every request coming into the system does not have to wait for a
	// single peer to decide if the rate limit has been reached.
	Behavior_GLOBAL Behavior = 2
	// Changes the behavior of the `Duration` field. When `Behavior` is set to `DURATION_IS_GREGORIAN`
	// the `Duration` of the rate limit is reset whenever the end of selected GREGORIAN calendar
	// interval is reached.
	//
	// Given the following `Duration` values
	//   0 = Minutes
	//   1 = Hours
	//   2 = Days
	//   3 = Weeks
	//   4 = Months
	//   5 = Years
	//
	// Examples when using `Behavior = DURATION_IS_GREGORIAN`
	//
	// If  `Duration = 2` (Days) then the rate limit will expire at the end of the current day the
	// rate limit was created.
	//
	// If `Duration = 0` (Minutes) then the rate limit will expire at the end of the current minute
	// the rate limit was created.
	//
	// If `Duration = 4` (Months) then the rate limit will expire at the end of the current month
	// the rate limit was created.
	Behavior_DURATION_IS_GREGORIAN Behavior = 4
	// If this flag is set causes the rate limit to reset any accrued hits stored in the cache, and will
	// ignore any `Hit` values provided in the current request. The effect this has is dependent on
	// algorithm chosen. For instance, if used with `TOKEN_BUCKET` it will immediately expire the
	// cache value. For `LEAKY_BUCKET` it sets the `Remaining` to `Limit`.
	Behavior_RESET_REMAINING Behavior = 8
	// Pushes rate limits to other regions
	Behavior_MULTI_REGION Behavior = 16
)

var Behavior_name = map[int32]string{
	0:  "BATCHING",
	1:  "NO_BATCHING",
	2:  "GLOBAL",
	4:  "DURATION_IS_GREGORIAN",
	8:  "RESET_REMAINING",
	16: "MULTI_REGION",
}

var Behavior_value = map[string]int32{
	"BATCHING":              0,
	"NO_BATCHING":           1,
	"GLOBAL":                2,
	"DURATION_IS_GREGORIAN": 4,
	"RESET_REMAINING":       8,
	"MULTI_REGION":          16,
}

func (x Behavior) String() string {
	return proto.EnumName(Behavior_name, int32(x))
}

func (Behavior) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{1}
}

type Status int32

const (
	Status_UNDER_LIMIT Status = 0
	Status_OVER_LIMIT  Status = 1
)

var Status_name = map[int32]string{
	0: "UNDER_LIMIT",
	1: "OVER_LIMIT",
}

var Status_value = map[string]int32{
	"UNDER_LIMIT": 0,
	"OVER_LIMIT":  1,
}

func (x Status) String() string {
	return proto.EnumName(Status_name, int32(x))
}

func (Status) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{2}
}

// Must specify at least one Request
type GetRateLimitsReq struct {
	Requests             []*RateLimitReq `protobuf:"bytes,1,rep,name=requests,proto3" json:"requests,omitempty"`
	XXX_NoUnkeyedLiteral struct{}        `json:"-"`
	XXX_unrecognized     []byte          `json:"-"`
	XXX_sizecache        int32           `json:"-"`
}

func (m *GetRateLimitsReq) Reset()         { *m = GetRateLimitsReq{} }
func (m *GetRateLimitsReq) String() string { return proto.CompactTextString(m) }
func (*GetRateLimitsReq) ProtoMessage()    {}
func (*GetRateLimitsReq) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{0}
}

func (m *GetRateLimitsReq) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_GetRateLimitsReq.Unmarshal(m, b)
}
func (m *GetRateLimitsReq) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_GetRateLimitsReq.Marshal(b, m, deterministic)
}
func (m *GetRateLimitsReq) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GetRateLimitsReq.Merge(m, src)
}
func (m *GetRateLimitsReq) XXX_Size() int {
	return xxx_messageInfo_GetRateLimitsReq.Size(m)
}
func (m *GetRateLimitsReq) XXX_DiscardUnknown() {
	xxx_messageInfo_GetRateLimitsReq.DiscardUnknown(m)
}

var xxx_messageInfo_GetRateLimitsReq proto.InternalMessageInfo

func (m *GetRateLimitsReq) GetRequests() []*RateLimitReq {
	if m != nil {
		return m.Requests
	}
	return nil
}

// RateLimits returned are in the same order as the Requests
type GetRateLimitsResp struct {
	Responses            []*RateLimitResp `protobuf:"bytes,1,rep,name=responses,proto3" json:"responses,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *GetRateLimitsResp) Reset()         { *m = GetRateLimitsResp{} }
func (m *GetRateLimitsResp) String() string { return proto.CompactTextString(m) }
func (*GetRateLimitsResp) ProtoMessage()    {}
func (*GetRateLimitsResp) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{1}
}

func (m *GetRateLimitsResp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_GetRateLimitsResp.Unmarshal(m, b)
}
func (m *GetRateLimitsResp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_GetRateLimitsResp.Marshal(b, m, deterministic)
}
func (m *GetRateLimitsResp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GetRateLimitsResp.Merge(m, src)
}
func (m *GetRateLimitsResp) XXX_Size() int {
	return xxx_messageInfo_GetRateLimitsResp.Size(m)
}
func (m *GetRateLimitsResp) XXX_DiscardUnknown() {
	xxx_messageInfo_GetRateLimitsResp.DiscardUnknown(m)
}

var xxx_messageInfo_GetRateLimitsResp proto.InternalMessageInfo

func (m *GetRateLimitsResp) GetResponses() []*RateLimitResp {
	if m != nil {
		return m.Responses
	}
	return nil
}

type RateLimitReq struct {
	// The name of the rate limit IE: 'requests_per_second', 'gets_per_minute`
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Uniquely identifies this rate limit IE: 'ip:10.2.10.7' or 'account:123445'
	UniqueKey string `protobuf:"bytes,2,opt,name=unique_key,json=uniqueKey,proto3" json:"unique_key,omitempty"`
	// Rate limit requests optionally specify the number of hits a request adds to the matched limit. If Hit
	// is zero, the request returns the current limit, but does not increment the hit count.
	Hits int64 `protobuf:"varint,3,opt,name=hits,proto3" json:"hits,omitempty"`
	// The number of requests that can occur for the duration of the rate limit
	Limit int64 `protobuf:"varint,4,opt,name=limit,proto3" json:"limit,omitempty"`
	// The duration of the rate limit in milliseconds
	// Second = 1000 Milliseconds
	// Minute = 60000 Milliseconds
	// Hour = 3600000 Milliseconds
	Duration int64 `protobuf:"varint,5,opt,name=duration,proto3" json:"duration,omitempty"`
	// The algorithm used to calculate the rate limit. The algorithm may change on
	// subsequent requests, when this occurs any previous rate limit hit counts are reset.
	Algorithm Algorithm `protobuf:"varint,6,opt,name=algorithm,proto3,enum=pb.gubernator.Algorithm" json:"algorithm,omitempty"`
	// Behavior is a set of int32 flags that control the behavior of the rate limit in gubernator
	Behavior             Behavior `protobuf:"varint,7,opt,name=behavior,proto3,enum=pb.gubernator.Behavior" json:"behavior,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *RateLimitReq) Reset()         { *m = RateLimitReq{} }
func (m *RateLimitReq) String() string { return proto.CompactTextString(m) }
func (*RateLimitReq) ProtoMessage()    {}
func (*RateLimitReq) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{2}
}

func (m *RateLimitReq) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RateLimitReq.Unmarshal(m, b)
}
func (m *RateLimitReq) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RateLimitReq.Marshal(b, m, deterministic)
}
func (m *RateLimitReq) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RateLimitReq.Merge(m, src)
}
func (m *RateLimitReq) XXX_Size() int {
	return xxx_messageInfo_RateLimitReq.Size(m)
}
func (m *RateLimitReq) XXX_DiscardUnknown() {
	xxx_messageInfo_RateLimitReq.DiscardUnknown(m)
}

var xxx_messageInfo_RateLimitReq proto.InternalMessageInfo

func (m *RateLimitReq) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *RateLimitReq) GetUniqueKey() string {
	if m != nil {
		return m.UniqueKey
	}
	return ""
}

func (m *RateLimitReq) GetHits() int64 {
	if m != nil {
		return m.Hits
	}
	return 0
}

func (m *RateLimitReq) GetLimit() int64 {
	if m != nil {
		return m.Limit
	}
	return 0
}

func (m *RateLimitReq) GetDuration() int64 {
	if m != nil {
		return m.Duration
	}
	return 0
}

func (m *RateLimitReq) GetAlgorithm() Algorithm {
	if m != nil {
		return m.Algorithm
	}
	return Algorithm_TOKEN_BUCKET
}

func (m *RateLimitReq) GetBehavior() Behavior {
	if m != nil {
		return m.Behavior
	}
	return Behavior_BATCHING
}

type RateLimitResp struct {
	// The status of the rate limit.
	Status Status `protobuf:"varint,1,opt,name=status,proto3,enum=pb.gubernator.Status" json:"status,omitempty"`
	// The currently configured request limit (Identical to RateLimitRequest.rate_limit_config.limit).
	Limit int64 `protobuf:"varint,2,opt,name=limit,proto3" json:"limit,omitempty"`
	// This is the number of requests remaining before the limit is hit.
	Remaining int64 `protobuf:"varint,3,opt,name=remaining,proto3" json:"remaining,omitempty"`
	// This is the time when the rate limit span will be reset, provided as a unix timestamp in milliseconds.
	ResetTime int64 `protobuf:"varint,4,opt,name=reset_time,json=resetTime,proto3" json:"reset_time,omitempty"`
	// Contains the error; If set all other values should be ignored
	Error string `protobuf:"bytes,5,opt,name=error,proto3" json:"error,omitempty"`
	// This is additional metadata that a client might find useful. (IE: Additional headers, corrdinator ownership, etc..)
	Metadata             map[string]string `protobuf:"bytes,6,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *RateLimitResp) Reset()         { *m = RateLimitResp{} }
func (m *RateLimitResp) String() string { return proto.CompactTextString(m) }
func (*RateLimitResp) ProtoMessage()    {}
func (*RateLimitResp) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{3}
}

func (m *RateLimitResp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RateLimitResp.Unmarshal(m, b)
}
func (m *RateLimitResp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RateLimitResp.Marshal(b, m, deterministic)
}
func (m *RateLimitResp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RateLimitResp.Merge(m, src)
}
func (m *RateLimitResp) XXX_Size() int {
	return xxx_messageInfo_RateLimitResp.Size(m)
}
func (m *RateLimitResp) XXX_DiscardUnknown() {
	xxx_messageInfo_RateLimitResp.DiscardUnknown(m)
}

var xxx_messageInfo_RateLimitResp proto.InternalMessageInfo

func (m *RateLimitResp) GetStatus() Status {
	if m != nil {
		return m.Status
	}
	return Status_UNDER_LIMIT
}

func (m *RateLimitResp) GetLimit() int64 {
	if m != nil {
		return m.Limit
	}
	return 0
}

func (m *RateLimitResp) GetRemaining() int64 {
	if m != nil {
		return m.Remaining
	}
	return 0
}

func (m *RateLimitResp) GetResetTime() int64 {
	if m != nil {
		return m.ResetTime
	}
	return 0
}

func (m *RateLimitResp) GetError() string {
	if m != nil {
		return m.Error
	}
	return ""
}

func (m *RateLimitResp) GetMetadata() map[string]string {
	if m != nil {
		return m.Metadata
	}
	return nil
}

type HealthCheckReq struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *HealthCheckReq) Reset()         { *m = HealthCheckReq{} }
func (m *HealthCheckReq) String() string { return proto.CompactTextString(m) }
func (*HealthCheckReq) ProtoMessage()    {}
func (*HealthCheckReq) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{4}
}

func (m *HealthCheckReq) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_HealthCheckReq.Unmarshal(m, b)
}
func (m *HealthCheckReq) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_HealthCheckReq.Marshal(b, m, deterministic)
}
func (m *HealthCheckReq) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HealthCheckReq.Merge(m, src)
}
func (m *HealthCheckReq) XXX_Size() int {
	return xxx_messageInfo_HealthCheckReq.Size(m)
}
func (m *HealthCheckReq) XXX_DiscardUnknown() {
	xxx_messageInfo_HealthCheckReq.DiscardUnknown(m)
}

var xxx_messageInfo_HealthCheckReq proto.InternalMessageInfo

type HealthCheckResp struct {
	// Valid entries are 'healthy' or 'unhealthy'
	Status string `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	// If 'unhealthy', message indicates the problem
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// The number of peers we know about
	PeerCount            int32    `protobuf:"varint,3,opt,name=peer_count,json=peerCount,proto3" json:"peer_count,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *HealthCheckResp) Reset()         { *m = HealthCheckResp{} }
func (m *HealthCheckResp) String() string { return proto.CompactTextString(m) }
func (*HealthCheckResp) ProtoMessage()    {}
func (*HealthCheckResp) Descriptor() ([]byte, []int) {
	return fileDescriptor_079522a6f9470154, []int{5}
}

func (m *HealthCheckResp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_HealthCheckResp.Unmarshal(m, b)
}
func (m *HealthCheckResp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_HealthCheckResp.Marshal(b, m, deterministic)
}
func (m *HealthCheckResp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HealthCheckResp.Merge(m, src)
}
func (m *HealthCheckResp) XXX_Size() int {
	return xxx_messageInfo_HealthCheckResp.Size(m)
}
func (m *HealthCheckResp) XXX_DiscardUnknown() {
	xxx_messageInfo_HealthCheckResp.DiscardUnknown(m)
}

var xxx_messageInfo_HealthCheckResp proto.InternalMessageInfo

func (m *HealthCheckResp) GetStatus() string {
	if m != nil {
		return m.Status
	}
	return ""
}

func (m *HealthCheckResp) GetMessage() string {
	if m != nil {
		return m.Message
	}
	return ""
}

func (m *HealthCheckResp) GetPeerCount() int32 {
	if m != nil {
		return m.PeerCount
	}
	return 0
}

func init() {
	proto.RegisterEnum("pb.gubernator.Algorithm", Algorithm_name, Algorithm_value)
	proto.RegisterEnum("pb.gubernator.Behavior", Behavior_name, Behavior_value)
	proto.RegisterEnum("pb.gubernator.Status", Status_name, Status_value)
	proto.RegisterType((*GetRateLimitsReq)(nil), "pb.gubernator.GetRateLimitsReq")
	proto.RegisterType((*GetRateLimitsResp)(nil), "pb.gubernator.GetRateLimitsResp")
	proto.RegisterType((*RateLimitReq)(nil), "pb.gubernator.RateLimitReq")
	proto.RegisterType((*RateLimitResp)(nil), "pb.gubernator.RateLimitResp")
	proto.RegisterMapType((map[string]string)(nil), "pb.gubernator.RateLimitResp.MetadataEntry")
	proto.RegisterType((*HealthCheckReq)(nil), "pb.gubernator.HealthCheckReq")
	proto.RegisterType((*HealthCheckResp)(nil), "pb.gubernator.HealthCheckResp")
}

func init() { proto.RegisterFile("gubernator.proto", fileDescriptor_079522a6f9470154) }

var fileDescriptor_079522a6f9470154 = []byte{
	// 712 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x7c, 0x54, 0xdd, 0x6e, 0xda, 0x48,
	0x14, 0x8e, 0x21, 0x21, 0xf8, 0x24, 0x80, 0x33, 0xbb, 0x49, 0xbc, 0x2c, 0xd9, 0x45, 0xbe, 0x62,
	0x91, 0x16, 0x14, 0x22, 0xed, 0xae, 0xb2, 0x57, 0x40, 0x5c, 0x62, 0x01, 0xb6, 0x34, 0x81, 0x48,
	0xed, 0x8d, 0x35, 0x24, 0x23, 0xb0, 0x82, 0x7f, 0xf0, 0x8c, 0x53, 0xe5, 0xae, 0xea, 0x2b, 0xf4,
	0x35, 0xfa, 0x36, 0xbd, 0xee, 0x5d, 0x1f, 0xa1, 0x0f, 0x50, 0x8d, 0x01, 0x83, 0x91, 0x9a, 0xbb,
	0x39, 0xdf, 0xf9, 0xce, 0x77, 0x3c, 0xdf, 0x07, 0x03, 0xca, 0x34, 0x9a, 0xd0, 0xd0, 0x23, 0xdc,
	0x0f, 0x1b, 0x41, 0xe8, 0x73, 0x1f, 0x15, 0x82, 0x49, 0x63, 0x03, 0x96, 0x2b, 0x53, 0xdf, 0x9f,
	0xce, 0x69, 0x93, 0x04, 0x4e, 0x93, 0x78, 0x9e, 0xcf, 0x09, 0x77, 0x7c, 0x8f, 0x2d, 0xc9, 0x5a,
	0x1f, 0x94, 0x1e, 0xe5, 0x98, 0x70, 0x3a, 0x70, 0x5c, 0x87, 0x33, 0x4c, 0x17, 0xe8, 0x5f, 0xc8,
	0x87, 0x74, 0x11, 0x51, 0xc6, 0x99, 0x2a, 0x55, 0xb3, 0xb5, 0xa3, 0xd6, 0xef, 0x8d, 0x94, 0x66,
	0x23, 0xe1, 0x63, 0xba, 0xc0, 0x09, 0x59, 0xb3, 0xe0, 0x64, 0x47, 0x8c, 0x05, 0xe8, 0x1a, 0xe4,
	0x90, 0xb2, 0xc0, 0xf7, 0x18, 0x5d, 0xcb, 0x55, 0x7e, 0x2e, 0xc7, 0x02, 0xbc, 0xa1, 0x6b, 0xdf,
	0x25, 0x38, 0xde, 0xde, 0x85, 0x10, 0xec, 0x7b, 0xc4, 0xa5, 0xaa, 0x54, 0x95, 0x6a, 0x32, 0x8e,
	0xcf, 0xe8, 0x02, 0x20, 0xf2, 0x9c, 0x45, 0x44, 0xed, 0x27, 0xfa, 0xa2, 0x66, 0xe2, 0x8e, 0xbc,
	0x44, 0xfa, 0xf4, 0x45, 0x8c, 0xcc, 0x1c, 0xce, 0xd4, 0x6c, 0x55, 0xaa, 0x65, 0x71, 0x7c, 0x46,
	0xbf, 0xc2, 0xc1, 0x5c, 0x48, 0xaa, 0xfb, 0x31, 0xb8, 0x2c, 0x50, 0x19, 0xf2, 0x8f, 0x51, 0x18,
	0xdb, 0xa3, 0x1e, 0xc4, 0x8d, 0xa4, 0x46, 0xff, 0x80, 0x4c, 0xe6, 0x53, 0x3f, 0x74, 0xf8, 0xcc,
	0x55, 0x73, 0x55, 0xa9, 0x56, 0x6c, 0xa9, 0x3b, 0xb7, 0x68, 0xaf, 0xfb, 0x78, 0x43, 0x45, 0x57,
	0x90, 0x9f, 0xd0, 0x19, 0x79, 0x76, 0xfc, 0x50, 0x3d, 0x8c, 0xc7, 0xce, 0x77, 0xc6, 0x3a, 0xab,
	0x36, 0x4e, 0x88, 0xda, 0xe7, 0x0c, 0x14, 0x52, 0x9e, 0xa0, 0xbf, 0x21, 0xc7, 0x38, 0xe1, 0x11,
	0x8b, 0x6f, 0x5e, 0x6c, 0x9d, 0xee, 0x88, 0xdc, 0xc5, 0x4d, 0xbc, 0x22, 0x6d, 0xee, 0x97, 0xd9,
	0xbe, 0x5f, 0x45, 0x24, 0xe1, 0x12, 0xc7, 0x73, 0xbc, 0xe9, 0xca, 0x8e, 0x0d, 0x20, 0x6c, 0x0c,
	0x29, 0xa3, 0xdc, 0xe6, 0x8e, 0x4b, 0x57, 0xc6, 0xc8, 0x31, 0x32, 0x72, 0x5c, 0x2a, 0x24, 0x69,
	0x18, 0xfa, 0x61, 0xec, 0x8c, 0x8c, 0x97, 0x05, 0x7a, 0x03, 0x79, 0x97, 0x72, 0xf2, 0x48, 0x38,
	0x51, 0x73, 0x71, 0xb6, 0xf5, 0xd7, 0xb2, 0x6d, 0x0c, 0x57, 0x64, 0xdd, 0xe3, 0xe1, 0x0b, 0x4e,
	0x66, 0xcb, 0xff, 0x43, 0x21, 0xd5, 0x42, 0x0a, 0x64, 0x45, 0x9a, 0xcb, 0x9c, 0xc5, 0x51, 0x7c,
	0xc0, 0x33, 0x99, 0x47, 0x74, 0x95, 0xf0, 0xb2, 0xb8, 0xce, 0xfc, 0x27, 0x69, 0x0a, 0x14, 0x6f,
	0x29, 0x99, 0xf3, 0x59, 0x77, 0x46, 0x1f, 0x9e, 0x30, 0x5d, 0x68, 0x13, 0x28, 0xa5, 0x10, 0x16,
	0xa0, 0xb3, 0x94, 0x83, 0x72, 0x62, 0x95, 0x0a, 0x87, 0x2e, 0x65, 0x8c, 0x4c, 0xd7, 0xc2, 0xeb,
	0x52, 0x18, 0x12, 0x50, 0x1a, 0xda, 0x0f, 0x7e, 0xe4, 0xf1, 0xd8, 0xaf, 0x03, 0x2c, 0x0b, 0xa4,
	0x2b, 0x80, 0x7a, 0x13, 0xe4, 0x24, 0x71, 0xa4, 0xc0, 0xf1, 0xc8, 0xea, 0xeb, 0xa6, 0xdd, 0x19,
	0x77, 0xfb, 0xfa, 0x48, 0xd9, 0x13, 0xc8, 0x40, 0x6f, 0xf7, 0xdf, 0xae, 0x11, 0xa9, 0xfe, 0x1e,
	0xf2, 0xeb, 0xac, 0xd1, 0x31, 0xe4, 0x3b, 0xed, 0x51, 0xf7, 0xd6, 0x30, 0x7b, 0xca, 0x1e, 0x2a,
	0xc1, 0x91, 0x69, 0xd9, 0x09, 0x20, 0x21, 0x80, 0x5c, 0x6f, 0x60, 0x75, 0xda, 0x03, 0x25, 0x83,
	0x7e, 0x83, 0xd3, 0x9b, 0x31, 0x6e, 0x8f, 0x0c, 0xcb, 0xb4, 0x8d, 0x3b, 0xbb, 0x87, 0xf5, 0x9e,
	0x85, 0x8d, 0xb6, 0xa9, 0xec, 0xa3, 0x5f, 0xa0, 0x84, 0xf5, 0x3b, 0x7d, 0x64, 0x63, 0x7d, 0xd8,
	0x36, 0x4c, 0x31, 0x9b, 0x17, 0x8b, 0x87, 0xe3, 0xc1, 0xc8, 0xb0, 0xb1, 0xde, 0x33, 0x2c, 0x53,
	0x51, 0xea, 0x7f, 0x41, 0x6e, 0xf9, 0xfb, 0x10, 0x8b, 0xc6, 0xe6, 0x8d, 0x8e, 0xed, 0x81, 0x31,
	0x34, 0xc4, 0x57, 0x16, 0x01, 0xac, 0xfb, 0xa4, 0x96, 0x5a, 0x5f, 0x25, 0xc8, 0xdc, 0x5f, 0xa2,
	0x00, 0x0a, 0xa9, 0x3f, 0x32, 0xfa, 0x73, 0x27, 0xd5, 0xdd, 0x37, 0xa3, 0x5c, 0x7d, 0x9d, 0xc0,
	0x02, 0xad, 0xf2, 0xf1, 0xcb, 0xb7, 0x4f, 0x99, 0x33, 0xed, 0xa4, 0xf9, 0x7c, 0xd9, 0x4c, 0xb5,
	0xaf, 0xa5, 0x3a, 0xa2, 0x70, 0xb4, 0x95, 0x18, 0xba, 0xd8, 0x91, 0x4b, 0xe7, 0x5b, 0xfe, 0xe3,
	0xb5, 0x36, 0x0b, 0xb4, 0xf3, 0x78, 0xd7, 0x09, 0x2a, 0x89, 0x5d, 0x5b, 0xcd, 0x4e, 0xe9, 0x1d,
	0x6c, 0xc6, 0x3e, 0x48, 0xd2, 0x24, 0x17, 0x3f, 0x83, 0x57, 0x3f, 0x02, 0x00, 0x00, 0xff, 0xff,
	0x67, 0x9a, 0x70, 0x17, 0x47, 0x05, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// V1Client is the client API for V1 service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type V1Client interface {
	// Given a list of rate limit requests, return the rate limits of each.
	GetRateLimits(ctx context.Context, in *GetRateLimitsReq, opts ...grpc.CallOption) (*GetRateLimitsResp, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(ctx context.Context, in *HealthCheckReq, opts ...grpc.CallOption) (*HealthCheckResp, error)
}

type v1Client struct {
	cc *grpc.ClientConn
}

func NewV1Client(cc *grpc.ClientConn) V1Client {
	return &v1Client{cc}
}

func (c *v1Client) GetRateLimits(ctx context.Context, in *GetRateLimitsReq, opts ...grpc.CallOption) (*GetRateLimitsResp, error) {
	out := new(GetRateLimitsResp)
	err := c.cc.Invoke(ctx, "/pb.gubernator.V1/GetRateLimits", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *v1Client) HealthCheck(ctx context.Context, in *HealthCheckReq, opts ...grpc.CallOption) (*HealthCheckResp, error) {
	out := new(HealthCheckResp)
	err := c.cc.Invoke(ctx, "/pb.gubernator.V1/HealthCheck", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// V1Server is the server API for V1 service.
type V1Server interface {
	// Given a list of rate limit requests, return the rate limits of each.
	GetRateLimits(context.Context, *GetRateLimitsReq) (*GetRateLimitsResp, error)
	// This method is for round trip benchmarking and can be used by
	// the client to determine connectivity to the server
	HealthCheck(context.Context, *HealthCheckReq) (*HealthCheckResp, error)
}

// UnimplementedV1Server can be embedded to have forward compatible implementations.
type UnimplementedV1Server struct {
}

func (*UnimplementedV1Server) GetRateLimits(ctx context.Context, req *GetRateLimitsReq) (*GetRateLimitsResp, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetRateLimits not implemented")
}
func (*UnimplementedV1Server) HealthCheck(ctx context.Context, req *HealthCheckReq) (*HealthCheckResp, error) {
	return nil, status.Errorf(codes.Unimplemented, "method HealthCheck not implemented")
}

func RegisterV1Server(s *grpc.Server, srv V1Server) {
	s.RegisterService(&_V1_serviceDesc, srv)
}

func _V1_GetRateLimits_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetRateLimitsReq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(V1Server).GetRateLimits(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.V1/GetRateLimits",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(V1Server).GetRateLimits(ctx, req.(*GetRateLimitsReq))
	}
	return interceptor(ctx, in, info, handler)
}

func _V1_HealthCheck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(HealthCheckReq)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(V1Server).HealthCheck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.gubernator.V1/HealthCheck",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(V1Server).HealthCheck(ctx, req.(*HealthCheckReq))
	}
	return interceptor(ctx, in, info, handler)
}

var _V1_serviceDesc = grpc.ServiceDesc{
	ServiceName: "pb.gubernator.V1",
	HandlerType: (*V1Server)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "GetRateLimits",
			Handler:    _V1_GetRateLimits_Handler,
		},
		{
			MethodName: "HealthCheck",
			Handler:    _V1_HealthCheck_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "gubernator.proto",
}
